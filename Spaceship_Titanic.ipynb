{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142d8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group \n",
    "the passenger is travelling with and pp is their number within the group. People in a group are often family members, \n",
    "but not always.\n",
    "\n",
    "HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "\n",
    "CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the \n",
    "voyage. Passengers in cryosleep are confined to their cabins.\n",
    "\n",
    "Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P \n",
    "for Port or S for Starboard.\n",
    "\n",
    "Destination - The planet the passenger will be debarking to.\n",
    "\n",
    "Age - The age of the passenger.\n",
    "\n",
    "VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
    "\n",
    "RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship \n",
    "Titanic's many luxury amenities.\n",
    "\n",
    "Name - The first and last names of the passenger.\n",
    "\n",
    "Transported - Whether the passenger was transported to another dimension. This is the target, the column you are \n",
    "trying to predict.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45342b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies for Download and Clean\n",
    "# run in terminal to use bigquery  \"pip install --upgrade google-cloud-bigquery\"\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "'/Users/spicious/Desktop/News Datasets/Resources/spaceship-titanic-387720-729aac731f9f.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4477e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies for Random Forest Model\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for Data Imputation\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn import impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'spaceship-titanic-387720'\n",
    "client = bigquery.Client(credentials= credentials,project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_Amenities = client.query(\"\"\"\n",
    "   SELECT *\n",
    "   FROM Starship_Titanic.Amenities\"\"\")\n",
    "\n",
    "query_PassengerInfo = client.query(\"\"\"\n",
    "   SELECT *\n",
    "   FROM Starship_Titanic.PassengerInfo\"\"\")\n",
    "\n",
    "query_PlanetInfo = client.query(\"\"\"\n",
    "   SELECT *\n",
    "   FROM Starship_Titanic.Planet\"\"\")\n",
    "\n",
    "results_Amenities = query_Amenities.result()\n",
    "results_PassengerInfo = query_PassengerInfo.result()\n",
    "results_PlanetInfo = query_PlanetInfo.result()\n",
    "\n",
    "Amenities_df = pd.DataFrame(results_Amenities)\n",
    "PassengerInfo_df = pd.DataFrame(results_PassengerInfo)\n",
    "PlanetInfo_df = pd.DataFrame(results_PlanetInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Amenities_df.loc[0][0])\n",
    "print(PassengerInfo_df.loc[0][0])\n",
    "print(PlanetInfo_df.loc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d974182",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amenities_sorted = pd.DataFrame()\n",
    "i = 0\n",
    "while i < 8:\n",
    "    Amenities_sorted[i] = Amenities_df[0].apply(lambda x: x[i])\n",
    "    i += 1\n",
    "\n",
    "Amenities_sorted = Amenities_sorted.rename(columns={0: \"PassengerId\", \n",
    "                   1: \"Cabin\", \n",
    "                   2: \"VIP\", \n",
    "                   3: \"RoomService\",\n",
    "                   4: \"FoodCourt\",\n",
    "                   5: \"ShoppingMall\",\n",
    "                   6: \"Spa\",\n",
    "                   7: \"VRDeck\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "PassengerInfo_sorted = pd.DataFrame()\n",
    "i = 0\n",
    "while i < 6:\n",
    "    PassengerInfo_sorted[i] = PassengerInfo_df[0].apply(lambda x: x[i])\n",
    "    i += 1\n",
    "    \n",
    "PassengerInfo_sorted = PassengerInfo_sorted.rename(columns={0: \"PassengerId\", \n",
    "                   1: \"Name\", \n",
    "                   2: \"HomePlanet\", \n",
    "                   3: \"Cabin\",\n",
    "                   4: \"Age\",\n",
    "                   5: \"Transported\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlanetInfo_sorted = pd.DataFrame()\n",
    "i = 0\n",
    "while i < 4:\n",
    "    PlanetInfo_sorted[i] = PlanetInfo_df[0].apply(lambda x: x[i])\n",
    "    i += 1\n",
    "    \n",
    "PlanetInfo_sorted = PlanetInfo_sorted.rename(columns={0: \"PassengerId\", \n",
    "                   1: \"HomePlanet\", \n",
    "                   2: \"Destination\", \n",
    "                   3: \"CryoSleep\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging tables\n",
    "merge_df = pd.merge(Amenities_sorted, PassengerInfo_sorted, on = 'PassengerId', how = 'inner')\n",
    "df = pd.merge(merge_df, PlanetInfo_sorted, on = 'PassengerId', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up Column Duplications\n",
    "df = df.drop(['Cabin_y', 'HomePlanet_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Columns\n",
    "df = df.rename(columns={'Cabin_x': \"Cabin\", \n",
    "                   'HomePlanet_x': \"HomePlanet\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Transported\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3317411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with missing null's in the training data column\n",
    "df = df[\"Transported\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e5e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dataframe\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6299367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns\n",
    "columns = list(df.columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152ad5ac",
   "metadata": {},
   "source": [
    "# Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a53911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plans\n",
    "'''\n",
    "1) Check for missing values in all columns\n",
    "1.5) Consider Imputation\n",
    "2) remove unnecessary columns such as PassengerId and Name\n",
    "3) Convert categorical variables into indicator variables for HomePlanet, CryoSleep, Deck, Side, Destination, VIP, Transported\n",
    "4) Split up Cabin column into three different features\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Cabin column in three different Columns\n",
    "df[['Deck','RoomNum','Side']] = df.Cabin.str.split(\"/\", expand = True)\n",
    "del df['Cabin']\n",
    "\n",
    "# Reorder dataset to make me happy\n",
    "df = df[['PassengerId',\n",
    " 'HomePlanet',\n",
    " 'CryoSleep',\n",
    " 'Deck',\n",
    " 'RoomNum',\n",
    " 'Side',\n",
    " 'Destination',\n",
    " 'Age',\n",
    " 'VIP',\n",
    " 'RoomService',\n",
    " 'FoodCourt',\n",
    " 'ShoppingMall',\n",
    " 'Spa',\n",
    " 'VRDeck',\n",
    " 'Name',\n",
    " 'Transported']]\n",
    "\n",
    "# Check to see everything is going to plan\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f588f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "del df['PassengerId']\n",
    "del df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check drops\n",
    "columns = list(df.columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825d3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examining missing values\n",
    "print(\"Missing values distribution: \")\n",
    "print(df.isnull().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e263d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check datatype in each column\n",
    "print(\"Column datatypes: \")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9373920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data\n",
    "print('HomePlanet', df[\"HomePlanet\"].unique())\n",
    "print('CryoSleep', df[\"CryoSleep\"].unique())\n",
    "print('Deck', df[\"Deck\"].unique())\n",
    "print('Side', df[\"Side\"].unique())\n",
    "print('Destination', df[\"Destination\"].unique())\n",
    "print('VIP', df[\"VIP\"].unique())\n",
    "print('Transported', df[\"Transported\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1076d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Transported\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb013356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Transported\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ad2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21a88826",
   "metadata": {},
   "source": [
    "# Dealing with NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee482c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna()\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='titanic.csv')  \n",
    "df.to_csv('titanic.zip', index=False,\n",
    "          compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68cf1ff",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set\n",
    "X = df_clean.copy()\n",
    "X.drop(\"Transported\", axis=1, inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b9b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target vector\n",
    "y = df_clean[\"Transported\"].values.reshape(-1, 1)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea050f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Categorical Variables\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a55393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c68da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random forest classifier instance\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and use .ravel()on the \"y_train\" data. \n",
    "rf_model = rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f0c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af238ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c30b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importance array\n",
    "importances = rf_model.feature_importances_\n",
    "# List the top 10 most important features\n",
    "importances_sorted = sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n",
    "importances_sorted[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664cac68",
   "metadata": {},
   "source": [
    "# Trying Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute int values with mean.\n",
    "\n",
    "titanic_df_impute = df.copy()\n",
    "\n",
    "mean_imputer = impute.SimpleImputer(strategy='mean')\n",
    "\n",
    "titanic_df_impute['Age'] = mean_imputer.fit_transform(titanic_df_impute['Age'].values.reshape(-1,1))\n",
    "titanic_df_impute['RoomService'] = mean_imputer.fit_transform(titanic_df_impute['RoomService'].values.reshape(-1,1))\n",
    "titanic_df_impute['FoodCourt'] = mean_imputer.fit_transform(titanic_df_impute['FoodCourt'].values.reshape(-1,1))\n",
    "titanic_df_impute['ShoppingMall'] = mean_imputer.fit_transform(titanic_df_impute['ShoppingMall'].values.reshape(-1,1))\n",
    "titanic_df_impute['Spa'] = mean_imputer.fit_transform(titanic_df_impute['Spa'].values.reshape(-1,1))\n",
    "titanic_df_impute['VRDeck'] = mean_imputer.fit_transform(titanic_df_impute['VRDeck'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ca556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if Mean Imputation was performed\n",
    "titanic_df_impute.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use ffil and fillna to fill object values with the value nearest to it\n",
    "titanic_df_impute['RoomNum'] = titanic_df_impute['RoomNum'].fillna(method='ffill')\n",
    "titanic_df_impute['HomePlanet'] = titanic_df_impute['HomePlanet'].fillna(method='ffill')\n",
    "titanic_df_impute['CryoSleep'] = titanic_df_impute['CryoSleep'].fillna(method='ffill')\n",
    "titanic_df_impute['Deck'] = titanic_df_impute['Deck'].fillna(method='ffill')\n",
    "titanic_df_impute['Side'] = titanic_df_impute['Side'].fillna(method='ffill')\n",
    "titanic_df_impute['VIP'] = titanic_df_impute['VIP'].fillna(method='ffill')\n",
    "titanic_df_impute['Destination'] = titanic_df_impute['Destination'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7230b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if categorical Imputation was performed\n",
    "titanic_df_impute.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890bb526",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca20fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
